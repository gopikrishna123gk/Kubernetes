Introduction:-

*) Kubernetes is a tool that helps us to run and manage applications in containers. It was developed by Google Lab in 2014
*) It is an open-source container orchestration platform that automates the deployment, management, and scaling of
  container-based applications in different kinds of environments like physical, virtual, and cloud-native computing foundations.
*) Containers are isolated from each other so that multiple containers can run on the same machine without interrupting anyone else.
*)  It works brilliantly with all cloud vendors ex:- public, hybrid, and on-premises

Features of Kubernetes:-

1) Automated Scheduling:–
      Kubernetes provides an advanced scheduler to launch containers on cluster nodes. It performs resource optimization.
2) Self-Healing Capabilities:–
       It provides rescheduling, replacing, and restarting the containers which are dead.
3) Automated Rollouts and Rollbacks:– 
      It supports rollouts and rollbacks for the desired state of the containerized application.
4) Horizontal Scaling and Load Balancing:–
       Kubernetes can scale up and scale down the application as per the requirements.
5) Resource Utilization:–
      Kubernetes provides resource utilization monitoring and optimization, ensuring containers are using their resources efficiently.
6) Support for multiple clouds and hybrid clouds:– 
      Kubernetes can be deployed on different cloud platforms and run containerized applications across multiple clouds.
7) Extensibility:–
      Kubernetes is very extensible and can be extended with custom plugins and controllers.
8) Community Support:- 
      Kubernetes has a large and active community with frequent updates, bug fixes, and new features being added.

Architecture of Kubernetes;-

  Kubernetes follows the client-server architecture where we have the master installed on one machine and the node on separate
  Linux machines. It follows the master-slave model, which uses a master to manage Docker containers across multiple Kubernetes nodes.

Kubernetes- Master Node Components :–

   Kubernetes master is responsible for managing the entire cluster, coordinates all activities inside the cluster, and communicates with 
   the worker nodes to keep the Kubernetes and your application running. This is the entry point of all administrative tasks. 

  1) API Server:– The API server is the entry point for all the REST commands used to control the cluster. All the administrative tasks are
                 done by the API server within the master node. If we want to create, delete, update or display in Kubernetes object it has 
                 to go through this API server.
  2) Scheduler:– It is a service in the master responsible for distributing the workload. It is responsible for tracking the utilization of 
                 the working load of each worker node and then placing the workload on which resources are available and can accept the workload. 
  3) Controller Manager:– Also known as controllers. It is a daemon that runs in a non terminating loop and is responsible for collecting and 
                          sending information to the API server. It regulates the Kubernetes cluster by performing lifestyle functions.
  4) etcd–: It is a distributed key-value lightweight database. In Kubernetes, it is a central database for storing the current cluster state at 
            any point in time and is also used to store the configuration details such as subnets, config maps, etc. 

 Kubernetes- Worker Node Components :–

     Kubernetes Worker node contains all the necessary services to manage the networking between the containers, communicate with the master node, 
     and assign resources to the containers scheduled. The components of the  Worker node are

  1) Kubelet:– It is a primary node agent which communicates with the master node and executes on each worker node inside the cluster. It gets the
              pod specifications through the API server and executes the container associated with the pods and ensures that the containers described
              in the pods are running and healthy. If kubelet notices any issues with the pods running on the worker nodes then it tries to restart the pod 
              on the same node. 
  2) Kube-Proxy:– It is the core networking component inside the Kubernetes cluster. It is responsible for maintaining the entire network configuration.
                  Kube-Proxy maintains the distributed network across all the nodes, pods, and containers and exposes the services across the outside world.
                  It acts as a network proxy and load balancer for a service on a single worker node and manages the network routing for TCP and UDP packets. 
  3) Pods:– A pod is a group of containers that are deployed together on the same host. With the help of pods, we can deploy multiple dependent containers
            together so it acts as a wrapper around these containers so we can interact and manage these containers primarily through pods. 
  4) Docker:– Docker is the containerization platform that is used to package your application and all its dependencies together in the form of containers to 
              make sure that your application works seamlessly in any environment which can be development (or) test or production. Docker is a tool designed
              to make it easier to create, deploy, and run applications by using containers.

Application of Kubernetes:-

 *) Microservices architecture
 *) Cloud-native development
 *) Continuous integration and delivery
 *) Hybrid and multi-cloud deployments
 *) High-performance computing
 *) Edge computing

Jobs:-

  The main function of a job is to create one or more pod and tracks about the success of pods. They ensure that the specified number of pods are completed
  successfully. When a specified number of successful run of pods is completed, then the job is considered complete.

Labels & Selectors:-

  Labels:-
    Labels are key-value pairs which are attached to pods, replication controller and services. They are used as identifying attributes for objects such as  
    pods and replication controller. They can be added to an object at creation time and can be added or modified at the run time.

  Selectors:-
     Labels do not provide uniqueness. In general, we can say many objects can carry the same labels. Labels selector are core grouping primitive in Kubernetes.
     They are used by the users to select a set of objects.

  Namespace:-

     Namespace provides an additional qualification to a resource name. This is helpful when multiple teams are using the same cluster and there is a potential
     of name collision. It can be as a virtual wall between multiple clusters.
   Functionality of Namespace:-
      *) Namespaces help pod-to-pod communication using the same namespace.
      *) Namespaces are virtual clusters that can sit on top of the same physical cluster.
      *) They provide logical separation between the teams and their environments

  Node:-

    A node is a working machine in Kubernetes cluster which is also known as a minion. They are working units which can be physical, VM, or a cloud instance.

 Service:-

   A service can be defined as a logical set of pods. It can be defined as an abstraction on the top of the pod which provides a single IP address and DNS name 
   by which pods can be accessed. With Service, it is very easy to manage load balancing configuration.

  Pod:-

    A pod is a collection of containers and its storage inside a node of a Kubernetes cluster. It is possible to create a pod with multiple containers inside it.
    For example, keeping a database container and data container in the same pod.
  Types of Pod
    There are 2 types of Pods 
      1) Single container pod
      2) Multi container pod

Replication Controller:-

   Replication Controller is one of the key features of Kubernetes, which is responsible for managing the pod lifecycle. It is responsible for making sure that the 
   specified number of pod replicas are running at any point of time. It is used in time when one wants to make sure that the specified number of pod (or) at least 
   one pod is running. 

Replica Sets:-

   Replica Set ensures how many replica of pod should be running. It can be considered as a replacement of replication controller.

Deployments:-

Deployments are upgraded and higher version of replication controller. They manage the deployment of replica sets which is also an upgraded version of the
replication controller.

  Changing the Deployment:-

    Updating :− The user can update the ongoing deployment before it is completed. In this, the existing deployment will be settled and new deployment will be created.
    Deleting :− The user can pause/cancel the deployment by deleting it before it is completed. Recreating the same deployment will resume it.
    Rollback :− We can roll back the deployment or the deployment in progress. The user can create or update the deployment by using DeploymentSpec.PodTemplateSpec
               = oldRC.PodTemplateSpec.

Volumes:-

    In Kubernetes, a volume can be thought of as a directory which is accessible to the containers in a pod
   Types of Kubernetes Volume:-
    *) emptyDir 
    *) hostPath 
    *) gcePersistentDisk 
    *) awsElasticBlockStore 
    *) nfs 
    *) iscsi 
    *) flocker 
    *) glusterfs 
    *) rbd
    *) cephfs
    *) gitRepo
    *) secret
    *) persistentVolumeClaim 
    *) downwardAPI 
    *) azureDiskVolume 

 Secrets:-

     Secrets can be defined as Kubernetes objects used to store sensitive data such as user name and passwords with encryption.
       There are multiple ways of creating secrets in Kubernetes.
          1) Creating from txt files.
          2) Creating from yaml file.

Network Policy:-

     Network Policy defines how the pods in the same namespace will communicate with each other and the network endpoint. It requires
     extensions/v1beta1/networkpolicies to be enabled in the runtime configuration in the API server.

Autoscaling:-

    Autoscaling is one of the key features in Kubernetes cluster. It is a feature in which the cluster is capable of increasing the number of 
    nodes as the demand for service response increases and decrease the number of nodes as the requirement decreases.




